{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Goal:\n",
    "\n",
    "Comment on the effectiveness of the three advertisement campaigns by calculating the most\n",
    "appropriate web analytics measures and presenting them in ways you see as most\n",
    "appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'facebook_advert', 'platform': 'windows', 'clickstream': ['advert_landing']}\n"
     ]
    }
   ],
   "source": [
    "#I changed the given function\n",
    "def turn_line_into_dictionary(line_of_file):\n",
    "    return {'source': line_of_file[0],\n",
    "            'platform': line_of_file[1],\n",
    "            'clickstream': line_of_file[2:],\n",
    "            }\n",
    "\n",
    "test_list = ['facebook_advert', 'windows', 'advert_landing']\n",
    "test_data_item = turn_line_into_dictionary(test_list)\n",
    "print(test_data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "import csv\n",
    "\n",
    "all_data = [] #this is one list with a bunch of dictionaries inside\n",
    "\n",
    "file = open('visitor_data_clickstream.csv')\n",
    "csv_reader = csv.reader(file)\n",
    "next(csv_reader)\n",
    "\n",
    "for row in csv_reader:\n",
    "    #print(row)\n",
    "    data_item_dictionary = turn_line_into_dictionary(row)\n",
    "    #print(data_item_dict)\n",
    "    \n",
    "    all_data.append(data_item_dictionary)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                     Task 1          \n",
    "Do the three campaigns perform differently, and what could these differences mean?\n",
    "    comparing FB, Linkedin, partner\n",
    "What measurements did you use to measure each campaignâ€™s performance?\n",
    "    drop out rate, bounce rate, conversion rate, visit length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sublist(all_info,source):\n",
    "    sublist = [dictionary['clickstream']\n",
    "              for dictionary in all_info\n",
    "              if dictionary['source'] == source]\n",
    "    return sublist\n",
    "\n",
    "def find_dropout(info_list):\n",
    "    psucc = 0\n",
    "    pstart = 0\n",
    "    for stream in info_list:\n",
    "        if 'purchase_start' in stream:\n",
    "            pstart +=1\n",
    "            #print('no')\n",
    "        if 'purchase_success' in stream:\n",
    "            psucc +=1\n",
    "            #print('yes')\n",
    "    return psucc/pstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Dropout Rates when source is adverts\n",
    "fb_list = create_sublist(all_data,'facebook_advert')\n",
    "print(fb_list[0:4])\n",
    "fb_drop_out = find_dropout(fb_list)\n",
    "print('FB Advert drop out rate is',fb_drop_out)\n",
    "\n",
    "#this is a list of all the desktop clickstreams\n",
    "linkedin_list = create_sublist(all_data,'linkedin_advert')\n",
    "linkedin_drop_out = find_dropout(linkedin_list)\n",
    "print('Linkedin Advert drop out rate is',linkedin_drop_out)\n",
    "\n",
    "#this is a list of all the desktop clickstreams\n",
    "partner_list = create_sublist(all_data,'partner_advert')\n",
    "partner_drop_out = find_dropout(partner_list)\n",
    "print('Partner Advert drop out rate is',partner_drop_out)\n",
    "\n",
    "#Basically this is telling me that none of the adverts led to a purchase success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rate(all_info,source_type,rate_type):\n",
    "        source_list=[dictionary\n",
    "                    for dictionary in all_info\n",
    "                    if dictionary['source'] ==source_type]\n",
    "        \n",
    "        if rate_type == 'bounce':\n",
    "            clickstreams_of_1 = 0\n",
    "            for dictionary in source_list:\n",
    "                if len(dictionary['clickstream']) == 1:\n",
    "                       clickstreams_of_1 +=1\n",
    "            bounce_rate = clickstreams_of_1/len(source_list)\n",
    "            return bounce_rate\n",
    "    \n",
    "        elif rate_type == 'conversion':\n",
    "            success_purchases = 0\n",
    "            for dictionary in source_list:\n",
    "                if 'purchase_success' in dictionary['clickstream']:\n",
    "                    success_purchases +=1\n",
    "            conversion_rate = success_purchases/len(source_list)\n",
    "            return conversion_rate\n",
    "        \n",
    "        elif rate_type == 'depth':\n",
    "            total_depth = 0\n",
    "            for dictionary in source_list:\n",
    "                total_depth += len(dictionary['clickstream'])\n",
    "            avg_depth = total_depth/len(source_list)\n",
    "            return avg_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_list = [dictionary['source']\n",
    "              for dictionary in all_data]\n",
    "unique_source_list = list(set(source_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding all Dropout Rates\n",
    "\n",
    "\n",
    "dropout_rate_list = [] #use a list\n",
    "for source in unique_source_list:\n",
    "    source_information_list = create_sublist(all_data,source)\n",
    "    dropout_rate_list.append(find_dropout(source_information_list))\n",
    "    \n",
    "dropout_rate_dict = dict(zip(unique_source_list,dropout_rate_list))\n",
    "print(dropout_rate_dict)\n",
    "#direct had the highest dropout rates, linkedin_advert has the highest dropout rate of all advertisements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Bounce Rates for all sources\n",
    "bounce_rate_list = [] #use a list\n",
    "for source in unique_source_list:\n",
    "    bounce_rate_list.append(find_rate(all_data,source,'bounce'))\n",
    "    \n",
    "bounce_rate_dict = dict(zip(unique_source_list,bounce_rate_list))\n",
    "print(bounce_rate_dict)\n",
    "#FB advert has the highest bounce rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion Rates\n",
    "conversion_rate_list = []\n",
    "for source in unique_source_list:\n",
    "    conversion_rate_list.append(find_rate(all_data,source,'conversion'))\n",
    "conversion_rate_dict = dict(zip(unique_source_list,conversion_rate_list))\n",
    "print(conversion_rate_dict)\n",
    "#direct has the best conversion rate, but linkedin has the best conversion rate of all the advertising specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longest Visits ####\n",
    "#I think this means finds the average page depth\n",
    "avg_depth_list = []\n",
    "for source in unique_source_list:\n",
    "    avg_depth_list.append(find_rate(all_data,source,'depth'))\n",
    "avg_depth_dict = dict(zip(unique_source_list,avg_depth_list))\n",
    "print(avg_depth_dict)\n",
    "#linkedin has the longest visits on avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                Task 2          \n",
    "\n",
    "Do the users from different platforms behave differently? There were concerns that some\n",
    "platforms struggled at a particular stage of the process, can you find these stages?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most common endpoint of the clickstream for each platform 'mac', \n",
    "#'unknown','android', ios, windows\n",
    "\n",
    "# maybe try and calculate the most common end of a clickstream after the purchase\n",
    "# start began"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_list = [dictionary['platform']\n",
    "              for dictionary in all_data]\n",
    "unique_platform_list = list(set(platform_list))\n",
    "print(unique_platform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_platform_list(all_info,platform):\n",
    "    sublist = [dictionary['clickstream'][-1] #-1 gives us the last word of each clickstream\n",
    "              for dictionary in all_info\n",
    "              if dictionary['platform'] == platform]\n",
    "    return sublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac_clickstreams = create_platform_list(all_data,'mac')\n",
    "#print(mac_platform[0:4])\n",
    "platform_clickstream_list = []\n",
    "for platform in unique_platform_list:\n",
    "    platform_clickstream_list.append(create_platform_list(all_data,platform))\n",
    "    \n",
    "platform_clickstream_dict = dict(zip(unique_platform_list,platform_clickstream_list))\n",
    "#print(platform_clickstream_dict['mac'][:])\n",
    "\n",
    "\n",
    "platform_list = ['ios', 'windows', 'mac','android', 'unknown'] \n",
    "# platform_clickstream_dict_copy = platform_clickstream_dict.copy\n",
    "# for platform in platform_list:\n",
    "#     platform_clickstream_dict_copy[]\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe use a list comprehension to make a list of the last item in every clickstream for each \n",
    "#platform. \n",
    "#Then, find all the unique values. Then make a loop to count how many times\n",
    "#these values were used. Then you know your most common end point for each platform\n",
    "unique_clicks = []\n",
    "final_clicks = []\n",
    "for platform in unique_platform_list:\n",
    "    final_clicks.append(platform_clickstream_dict[platform][:])\n",
    "    unique_clicks.append(platform_clickstream_dict[platform][:])\n",
    "\n",
    "unique_clicks_1 =  unique_clicks[0]\n",
    "unique_clicks_final = list(set(unique_clicks_1))\n",
    "# print(unique_clicks_final)\n",
    "# print(len(unique_clicks_final))\n",
    "\n",
    "platform_terminal_clickstreams = dict(zip(unique_platform_list,final_clicks)) #this is a dictionary \n",
    "#that has all of the final clickstream values for each platform\n",
    "#print(platform_terminal_clickstreams['mac'][0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_platform_list_after_purchase_start(all_info,platform):\n",
    "    sublist = [dictionary['clickstream'] #-1 gives us the last word of each clickstream\n",
    "              for dictionary in all_info\n",
    "              if dictionary['platform'] == platform and 'purchase_start' in dictionary['clickstream']]\n",
    "    \n",
    "    \n",
    "    return sublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "  \n",
    "# def most_frequent(List): \n",
    "#     occurence_count = Counter(List) \n",
    "#     return occurence_count.most_common(9)#(1)[0][0]  #technically this is a tuple, can convert to a list in the append statement below\n",
    "\n",
    "def most_frequent(List): \n",
    "        occurence_count = Counter(List) \n",
    "        return occurence_count.most_common(9)#(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_clickstream_after_start_list = []\n",
    "for platform in unique_platform_list:\n",
    "    platform_clickstream_after_start_list.append(create_platform_list_after_purchase_start(all_data,platform))\n",
    " \n",
    "\n",
    "platform_clickstream_after_start_dict = dict(zip(unique_platform_list,platform_clickstream_after_start_list))\n",
    "platform_clickstream_after_start_dict['mac'][0]\n",
    "\n",
    "\n",
    "my_dict = {\"ios\":[],\"windows\":[],\"mac\":[], 'android':[], 'unknown':[] }\n",
    "for platform in unique_platform_list:\n",
    "    end_clicks = [stream[-1]\n",
    "                 for stream in platform_clickstream_after_start_dict[platform]\n",
    "                 if 'purchase_success' not in stream] \n",
    "    my_dict[platform].append(end_clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_end_clicks_after_purchase_start = []\n",
    "for platform in unique_platform_list:\n",
    "    most_frequent_end_clicks_after_purchase_start.append(most_frequent(my_dict[platform][0]))\n",
    "\n",
    "most_frequent_end_clicks_after_purchase_start_dict = dict(zip(unique_platform_list,most_frequent_end_clicks_after_purchase_start))\n",
    "pp.pprint(most_frequent_end_clicks_after_purchase_start_dict)\n",
    "\n",
    "##These are most common final clicks IF A PURCHASE START BEGINS when a purchase is not completed!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#################################################\n",
    "#################################################\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_end_clicks = []\n",
    "for platform in unique_platform_list:\n",
    "    most_frequent_end_clicks.append(most_frequent(platform_terminal_clickstreams[platform][:]))\n",
    "#print(most_frequent_end_clicks)\n",
    "platform_most_frequent_end_clicks = dict(zip(unique_platform_list,most_frequent_end_clicks))\n",
    "pp.pprint(platform_most_frequent_end_clicks)\n",
    "\n",
    "#Is it important that the most common final click in each clickstream is 'contact_us' or should that be expected?\n",
    "#Does it mean they have a questioned that couldnt be resolved on their own? Is there something going wrong\n",
    "#in the customer purchasing experience?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                Task 3          \n",
    "How does performance of users coming via adverts compare with those that came via\n",
    "social media shares? How about those who came to the site directly, or via search engine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#->seems like conversion rate is most important metric here (What gets the most purchase success)\n",
    "\n",
    "print(conversion_rate_dict)\n",
    "\n",
    "#FB share much better than FB advert\n",
    "#Linkedin advert better than Linkedin share\n",
    "#Direct has the highest conversion rate\n",
    "#Search is the 3rd highest\n",
    "#Will need to dig into these more but from quick glance it seems like each platform should be \n",
    "#addressed differently. FB shares are better, maybe ppl are more skeptical of what they see on FB\n",
    "#but will trust what their friends share. Linkedin might be seen as a more trustworthy sight in terms of the \n",
    "#automatically generted material and there is less of a need to be skeptical. It makes sense direct is the most \n",
    "#succesful because ppl specifcally chose to go to that website to browse or shop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dropout_rate_dict)\n",
    "#Direct has the highest dropout rate...hmm. Need to do some more digging here considering that it has the highest\n",
    "#conversion rate. Does this mean that direct access will start the most transactions overall? \n",
    "#Facebook advert has the lowest dropout rate. Basically does that mean that when people start a purchase, they\n",
    "#are mostly likely to complete it if they started from a facebook advert?\n",
    "#I feel like this stuff is a lesson in human phsycology. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                Task 4          \n",
    "Which blog converts better? (so that you know you should write more of similar ones in\n",
    "the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# basically just need to see which blog has the highest number of \n",
    "#'purchase successes' in the same clickstream\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a list of all of the clickstreams that with blogs\n",
    "blog_clickstreams = [dictionary['clickstream']\n",
    "                 for dictionary in all_data\n",
    "                 if ('blog_1' in dictionary['clickstream'] or 'blog_2' in dictionary['clickstream'])\n",
    "                    and 'purchase_success' in dictionary['clickstream']]\n",
    "print(len(blog_clickstreams))\n",
    "print(blog_clickstreams[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a list of all the clickstreams with purchase success of either blog1 or blog2\n",
    "blog_clickstreams_purchase_success = [dictionary['clickstream']\n",
    "                 for dictionary in all_data\n",
    "                 if ('blog_1' in dictionary['clickstream'] or 'blog_2' in dictionary['clickstream']) and\n",
    "                    'purchase_success' in dictionary['clickstream']]\n",
    "print(len(blog_clickstreams))\n",
    "print(blog_clickstreams[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_blog_conversion(all_info,blog):\n",
    "    blog_clickstream = [dictionary['clickstream']\n",
    "                       for dictionary in all_info\n",
    "                       if blog in dictionary['clickstream']]\n",
    "  \n",
    "    success_purchases = 0\n",
    "    for clickstream in blog_clickstream:\n",
    "        if 'purchase_success' in clickstream:\n",
    "            success_purchases +=1\n",
    "    conversion_rate = success_purchases/len(blog_clickstream)\n",
    "    return conversion_rate    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_1_converstion = find_blog_conversion(all_data,'blog_1')\n",
    "print(blog_1_converstion)\n",
    "blog_2_converstion = find_blog_conversion(all_data,'blog_2')\n",
    "print(blog_2_converstion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion after finding blog mentioned BEFORE the purchase success\n",
    "#doesnt include clickstream if both blogs are mentioned before purchase success and \n",
    "#if no blogs are mentioned purchase success this information is also not included in calculation\n",
    "def find_blog_conversion_exact(all_info,blog,other_blog):\n",
    "    blog_clickstream = [dictionary['clickstream']\n",
    "                       for dictionary in all_info\n",
    "                       if blog in dictionary['clickstream'] and other_blog not in dictionary['clickstream']]\n",
    "  \n",
    "    success_purchases = 0\n",
    "    for clickstream in blog_clickstream:\n",
    "        if 'purchase_success' in clickstream and clickstream.index(blog) < clickstream.index('purchase_success'):\n",
    "            success_purchases +=1\n",
    "    conversion_rate = success_purchases/len(blog_clickstream)\n",
    "    return conversion_rate    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_1_conv = find_blog_conversion_exact(all_data,'blog_1','blog_2')\n",
    "print(blog_1_conv)\n",
    "blog_2_conv = find_blog_conversion_exact(all_data,'blog_2','blog_1')\n",
    "print(blog_2_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_clicks_purchases = [clicks\n",
    "                            for clicks in blog_clickstreams\n",
    "                            if 'purchase_start' in clicks]\n",
    "print(len(blog_clicks_purchases))\n",
    "print(blog_clicks_purchases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
